{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import setuptools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/final_dataset.json\"\n",
    "df = pd.read_json(filename)\n",
    "df.head()\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89063"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_threshold = datetime.datetime.today().year + 10\n",
    "# Keep rows where the condition is true \n",
    "df = df.loc[\n",
    "    (df[\"Price\"] < 15000000) &\n",
    "    (df[\"ConstructionYear\"] <= year_threshold) | (pd.isna(df[\"ConstructionYear\"]))&\n",
    "    ~((df[\"GardenArea\"] > 0) & (df[\"Garden\"] == 0)) &\n",
    "    ~((df[\"GardenArea\"] > 0) & (df[\"Garden\"] == 0)) &\n",
    "    (df[\"ShowerCount\"] < 30) &\n",
    "    (df[\"ToiletCount\"] < 50)     \n",
    "]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of Missing Values:\n",
      " Url                   0.000000\n",
      "BathroomCount         5.061586\n",
      "BedroomCount          0.000000\n",
      "ConstructionYear     22.645768\n",
      "Country               0.000000\n",
      "District              0.004491\n",
      "Fireplace            96.044373\n",
      "FloodingZone         44.673995\n",
      "Furnished            72.357769\n",
      "Garden               79.627904\n",
      "GardenArea           79.627904\n",
      "Kitchen              36.621268\n",
      "LivingArea            9.264229\n",
      "Locality              0.000000\n",
      "MonthlyCharges       89.271639\n",
      "NumberOfFacades      31.016247\n",
      "PEB                  24.871159\n",
      "PostalCode            0.000000\n",
      "Price                 0.000000\n",
      "PropertyId            0.000000\n",
      "Province              0.004491\n",
      "Region                0.004491\n",
      "RoomCount            73.470465\n",
      "ShowerCount          38.943220\n",
      "StateOfBuilding      28.129526\n",
      "SubtypeOfProperty     0.000000\n",
      "SurfaceOfPlot        51.634236\n",
      "SwimmingPool         64.604830\n",
      "Terrace              39.822373\n",
      "ToiletCount          10.460011\n",
      "TypeOfProperty        0.000000\n",
      "TypeOfSale            0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_values = df.isna().sum()\n",
    "total_values = len(df)\n",
    "missing_percentage = (missing_values / total_values) * 100\n",
    "\n",
    "print(\"\\nPercentage of Missing Values:\\n\", missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83446 rows of data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df.drop([\"Fireplace\", \"Furnished\",\"PropertyId\",\"Region\", \"Country\", \"SubtypeOfProperty\", \"Url\", \"MonthlyCharges\", \"RoomCount\"], axis = 1, inplace=True)\n",
    "df.dropna(subset=['Locality', 'District', \"StateOfBuilding\", \"LivingArea\"], how='all', inplace=True)\n",
    "df.drop_duplicates(inplace= True)\n",
    "\n",
    "exclude_annuity = [\"annuity_monthly_amount\", \"annuity_without_lump_sum\", \"annuity_lump_sum\", \"homes_to_build\"]\n",
    "df = df[~df[\"TypeOfSale\"].isin(exclude_annuity)]\n",
    "\n",
    "print(\"There are {} rows of data\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if df[\"TypeOfSale\"].dtype == 'O' : \n",
    "    df = df.loc[df['TypeOfSale'].isin(['residential_sale', 'residential_monthly_rent'])]\n",
    "    df[\"TypeOfSale\"] = df[\"TypeOfSale\"].apply(lambda x : 0 if x == \"residential_sale\" else 1)\n",
    "\n",
    "df[\"TypeOfProperty\"] = df[\"TypeOfProperty\"].apply(lambda x : 0 if x == 1 else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the plausible value \n",
    "valid_peb_values = ['D', 'B', 'F', 'E', 'C', 'A', 'G', 'A++', 'A+', None]\n",
    "df = df.loc[df[\"PEB\"].isin(valid_peb_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values= None, strategy='constant', fill_value='Unknown')\n",
    "df['PEB'] = imputer.fit_transform(df[['PEB']]).flatten()\n",
    "imputer = SimpleImputer(missing_values= None, strategy='constant', fill_value='Unknown')\n",
    "df['StateOfBuilding'] = imputer.fit_transform(df[['StateOfBuilding']]).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Unknown','A++', 'A+', 'A', 'B', 'C', 'D', 'E', 'F', 'G']])\n",
    "df[\"PEB\"] = ordinal_encoder.fit_transform(df[[\"PEB\"]])\n",
    "\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Unknown','AS_NEW','JUST_RENOVATED','GOOD','TO_RESTORE','TO_RENOVATE','TO_BE_DONE_UP']])\n",
    "df[\"StateOfBuilding\"] = ordinal_encoder.fit_transform(df[[\"StateOfBuilding\"]])\n",
    "\n",
    "binary_kitchen_mapping = {\n",
    "    None : 0 , \n",
    "    'USA_HYPER_EQUIPPED': 1,\n",
    "    'NOT_INSTALLED': 0,\n",
    "    'USA_UNINSTALLED': 0,\n",
    "    'SEMI_EQUIPPED': 1,\n",
    "    'USA_SEMI_EQUIPPED': 1,\n",
    "    'INSTALLED': 1,\n",
    "    'USA_INSTALLED': 1,\n",
    "    'HYPER_EQUIPPED': 1,\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the new binary column\n",
    "df['Kitchen'] = df['Kitchen'].map(binary_kitchen_mapping)\n",
    "df[[\"Kitchen\"]]\n",
    "\n",
    "binary_flooding_mapping = {\n",
    "    None : 0 ,\n",
    "    'NON_FLOOD_ZONE': 0,\n",
    "    'RECOGNIZED_N_CIRCUMSCRIBED_FLOOD_ZONE': 0,\n",
    "    'RECOGNIZED_FLOOD_ZONE': 1,\n",
    "    'RECOGNIZED_N_CIRCUMSCRIBED_WATERSIDE_FLOOD_ZONE': 1,\n",
    "    'CIRCUMSCRIBED_FLOOD_ZONE': 1,\n",
    "    'CIRCUMSCRIBED_WATERSIDE_ZONE': 1,\n",
    "    'POSSIBLE_N_CIRCUMSCRIBED_FLOOD_ZONE': 1,\n",
    "    'POSSIBLE_FLOOD_ZONE': 1,\n",
    "    'POSSIBLE_N_CIRCUMSCRIBED_WATERSIDE_ZONE': 1,\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the new binary column\n",
    "df['FloodingZone'] = df['FloodingZone'].map(binary_flooding_mapping)\n",
    "df[[\"FloodingZone\"]]\n",
    "\n",
    "df.loc[df['NumberOfFacades'] > 4, 'NumberOfFacades'] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BathroomCount': 4335,\n",
       " 'BedroomCount': 0,\n",
       " 'ConstructionYear': 19000,\n",
       " 'District': 4,\n",
       " 'FloodingZone': 0,\n",
       " 'Garden': 0,\n",
       " 'GardenArea': 0,\n",
       " 'Kitchen': 0,\n",
       " 'LivingArea': 7879,\n",
       " 'Locality': 0,\n",
       " 'NumberOfFacades': 25227,\n",
       " 'PEB': 0,\n",
       " 'PostalCode': 0,\n",
       " 'Price': 0,\n",
       " 'Province': 4,\n",
       " 'ShowerCount': 32311,\n",
       " 'StateOfBuilding': 0,\n",
       " 'SurfaceOfPlot': 0,\n",
       " 'SwimmingPool': 0,\n",
       " 'Terrace': 0,\n",
       " 'ToiletCount': 8791,\n",
       " 'TypeOfProperty': 0,\n",
       " 'TypeOfSale': 0}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna({\"Garden\" : 0}, inplace=True)\n",
    "df.fillna({\"SwimmingPool\" : 0}, inplace=True)\n",
    "df.fillna({\"Terrace\" : 0}, inplace=True)\n",
    "df.loc[(df[\"TypeOfProperty\"] == 1) & (df[\"SurfaceOfPlot\"].isna()), \"SurfaceOfPlot\"] = 0\n",
    "df.loc[(df[\"Garden\"] == 0) & (df[\"GardenArea\"].isna()), \"GardenArea\"] = 0\n",
    "\n",
    "df.isna().sum().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    StateOfBuilding  FloodingZone  Kitchen  PEB  SurfaceOfPlot  \\\n",
      "2               3.0           0.0      0.0  0.0            0.0   \n",
      "6               3.0           0.0      0.0  6.0          130.0   \n",
      "8               3.0           0.0      1.0  4.0            0.0   \n",
      "11              1.0           0.0      0.0  4.0            0.0   \n",
      "14              1.0           0.0      1.0  7.0            0.0   \n",
      "\n",
      "    ConstructionYear  NumberOfFacades  \n",
      "2             1969.0              2.0  \n",
      "6             1920.0              3.0  \n",
      "8             2008.0              2.0  \n",
      "11            1972.0              2.0  \n",
      "14            1994.0              2.0  \n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "# List of columns to be imputed\n",
    "columns_to_impute = [\"StateOfBuilding\", \"FloodingZone\", \"Kitchen\", \"PEB\", \"SurfaceOfPlot\", \"ConstructionYear\", \"NumberOfFacades\" ]\n",
    "\n",
    "# Fit and transform the data\n",
    "df[columns_to_impute] = imputer.fit_transform(df[columns_to_impute])\n",
    "for col in columns_to_impute : \n",
    "    df[col] = round(df[col])\n",
    "# Display the transformed columns\n",
    "print(df[columns_to_impute].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BathroomCount', 'BedroomCount', 'ConstructionYear', 'FloodingZone',\n",
       "       'Garden', 'GardenArea', 'Kitchen', 'LivingArea', 'NumberOfFacades',\n",
       "       'PEB', 'PostalCode', 'Price', 'ShowerCount', 'StateOfBuilding',\n",
       "       'SurfaceOfPlot', 'SwimmingPool', 'Terrace', 'ToiletCount',\n",
       "       'TypeOfProperty', 'TypeOfSale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"Locality\", \"District\", \"Province\"], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BathroomCount        4335\n",
       "BedroomCount            0\n",
       "ConstructionYear        0\n",
       "FloodingZone            0\n",
       "Garden                  0\n",
       "GardenArea              0\n",
       "Kitchen                 0\n",
       "LivingArea           7879\n",
       "NumberOfFacades         0\n",
       "PEB                     0\n",
       "PostalCode              0\n",
       "Price                   0\n",
       "ShowerCount         32311\n",
       "StateOfBuilding         0\n",
       "SurfaceOfPlot           0\n",
       "SwimmingPool            0\n",
       "Terrace                 0\n",
       "ToiletCount          8791\n",
       "TypeOfProperty          0\n",
       "TypeOfSale              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"Price\"], axis = 1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor = xgb.XGBRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# # Predict and evaluate\n",
    "# y_pred = regressor.predict(X_test)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# score_train = regressor.score(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(f'Mean Absolute Error: {mae}')\n",
    "# print(f'R-squared: {r2}')\n",
    "# print(f'Score train: {score_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from xgboost import XGBRFRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "\n",
    "# X = df.drop(columns=[\"Price\"], axis = 1)\n",
    "# y = df[\"Price\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size= 0.2)\n",
    "\n",
    "\n",
    "# # Initialize the model with the best parameters\n",
    "# regressor = xgb.XGBRFRegressor(max_depth=50)\n",
    "\n",
    "# # cross_val_scores = cross_val_score(regressor, X, y, cv=10)\n",
    "# # # Print the cross-validation scores for each fold\n",
    "# # print(\"Cross-validation scores for each fold:\", cross_val_scores)\n",
    "# # # Print the mean cross-validation score\n",
    "# # print(\"Mean cross-validation score:\", cross_val_scores.mean())\n",
    "\n",
    "# # Train the model\n",
    "# regressor.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = True)\n",
    "\n",
    "# # Predict and evaluate\n",
    "# y_pred = regressor.predict(X_test)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# score_train = regressor.score(X_train, y_train)\n",
    "\n",
    "\n",
    "# print(f'Mean Absolute Error: {mae}')\n",
    "# print(f'R-squared: {r2}')\n",
    "# print(f'Score train: {score_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for each fold: [0.82119668 0.77941024 0.72666525 0.81205142 0.80155497 0.81135844\n",
      " 0.80256396 0.76320163 0.76527555 0.76567496]\n",
      "Mean cross-validation score: 0.7848953115931596\n",
      "Mean Absolute Error: 78474.25173506683\n",
      "R-squared: 0.8003844739504511\n",
      "Score train: 0.9700837460724501\n",
      "Score test: 0.8003844739504511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(columns=[\"Price\"], axis=1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "\n",
    "# Initialize the regressor\n",
    "regressor = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(regressor, X, y, cv=10)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"Cross-validation scores for each fold:\", cross_val_scores)\n",
    "\n",
    "# Print the mean cross-validation score\n",
    "print(\"Mean cross-validation score:\", cross_val_scores.mean())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "score_train = regressor.score(X_train, y_train)\n",
    "score_test = regressor.score(X_test, y_test)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Score train: {score_train}')\n",
    "print(f'Score test: {score_test}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
