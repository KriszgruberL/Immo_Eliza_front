{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import setuptools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118714\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/final_dataset.json\"\n",
    "df = pd.read_json(filename)\n",
    "df.head()\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89063"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_threshold = datetime.datetime.today().year + 10\n",
    "# Keep rows where the condition is true \n",
    "df = df.loc[\n",
    "    (df[\"Price\"] < 15000000) &\n",
    "    (df[\"ConstructionYear\"] <= year_threshold) | (pd.isna(df[\"ConstructionYear\"]))&\n",
    "    ~((df[\"GardenArea\"] > 0) & (df[\"Garden\"] == 0)) &\n",
    "    ~((df[\"GardenArea\"] > 0) & (df[\"Garden\"] == 0)) &\n",
    "    (df[\"ShowerCount\"] < 30) &\n",
    "    (df[\"ToiletCount\"] < 50)     \n",
    "]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83446 rows of data\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"Fireplace\", \"Furnished\",\"PropertyId\",\"Region\", \"Country\", \"SubtypeOfProperty\", \"Url\", \"MonthlyCharges\", \"RoomCount\"], axis = 1, inplace=True)\n",
    "df.dropna(subset=['Locality', 'District', \"StateOfBuilding\", \"LivingArea\"], how='all', inplace=True)\n",
    "df.drop_duplicates(inplace= True)\n",
    "\n",
    "exclude_annuity = [\"annuity_monthly_amount\", \"annuity_without_lump_sum\", \"annuity_lump_sum\", \"homes_to_build\"]\n",
    "df = df[~df[\"TypeOfSale\"].isin(exclude_annuity)]\n",
    "\n",
    "print(\"There are {} rows of data\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if df[\"TypeOfSale\"].dtype == 'O' : \n",
    "    df = df.loc[df['TypeOfSale'].isin(['residential_sale', 'residential_monthly_rent'])]\n",
    "    df[\"TypeOfSale\"] = df[\"TypeOfSale\"].apply(lambda x : 0 if x == \"residential_sale\" else 1)\n",
    "\n",
    "df[\"TypeOfProperty\"] = df[\"TypeOfProperty\"].apply(lambda x : 0 if x == 1 else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the plausible value \n",
    "valid_peb_values = ['D', 'B', 'F', 'E', 'C', 'A', 'G', 'A++', 'A+', None]\n",
    "df = df.loc[df[\"PEB\"].isin(valid_peb_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values= None, strategy='constant', fill_value='Unknown')\n",
    "df['PEB'] = imputer.fit_transform(df[['PEB']]).flatten()\n",
    "imputer = SimpleImputer(missing_values= None, strategy='constant', fill_value='Unknown')\n",
    "df['StateOfBuilding'] = imputer.fit_transform(df[['StateOfBuilding']]).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Unknown','A++', 'A+', 'A', 'B', 'C', 'D', 'E', 'F', 'G']])\n",
    "df[\"PEB\"] = ordinal_encoder.fit_transform(df[[\"PEB\"]])\n",
    "\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Unknown','AS_NEW','JUST_RENOVATED','GOOD','TO_RESTORE','TO_RENOVATE','TO_BE_DONE_UP']])\n",
    "df[\"StateOfBuilding\"] = ordinal_encoder.fit_transform(df[[\"StateOfBuilding\"]])\n",
    "\n",
    "binary_kitchen_mapping = {\n",
    "    None : 0 , \n",
    "    'USA_HYPER_EQUIPPED': 1,\n",
    "    'NOT_INSTALLED': 0,\n",
    "    'USA_UNINSTALLED': 0,\n",
    "    'SEMI_EQUIPPED': 1,\n",
    "    'USA_SEMI_EQUIPPED': 1,\n",
    "    'INSTALLED': 1,\n",
    "    'USA_INSTALLED': 1,\n",
    "    'HYPER_EQUIPPED': 1,\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the new binary column\n",
    "df['Kitchen'] = df['Kitchen'].map(binary_kitchen_mapping)\n",
    "df[[\"Kitchen\"]]\n",
    "\n",
    "binary_flooding_mapping = {\n",
    "    None : 0 ,\n",
    "    'NON_FLOOD_ZONE': 0,\n",
    "    'RECOGNIZED_N_CIRCUMSCRIBED_FLOOD_ZONE': 0,\n",
    "    'RECOGNIZED_FLOOD_ZONE': 1,\n",
    "    'RECOGNIZED_N_CIRCUMSCRIBED_WATERSIDE_FLOOD_ZONE': 1,\n",
    "    'CIRCUMSCRIBED_FLOOD_ZONE': 1,\n",
    "    'CIRCUMSCRIBED_WATERSIDE_ZONE': 1,\n",
    "    'POSSIBLE_N_CIRCUMSCRIBED_FLOOD_ZONE': 1,\n",
    "    'POSSIBLE_FLOOD_ZONE': 1,\n",
    "    'POSSIBLE_N_CIRCUMSCRIBED_WATERSIDE_ZONE': 1,\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the new binary column\n",
    "df['FloodingZone'] = df['FloodingZone'].map(binary_flooding_mapping)\n",
    "df[[\"FloodingZone\"]]\n",
    "\n",
    "df.loc[df['NumberOfFacades'] > 4, 'NumberOfFacades'] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BathroomCount': 4335,\n",
       " 'BedroomCount': 0,\n",
       " 'ConstructionYear': 19000,\n",
       " 'District': 4,\n",
       " 'FloodingZone': 0,\n",
       " 'Garden': 0,\n",
       " 'GardenArea': 0,\n",
       " 'Kitchen': 0,\n",
       " 'LivingArea': 7879,\n",
       " 'Locality': 0,\n",
       " 'NumberOfFacades': 25227,\n",
       " 'PEB': 0,\n",
       " 'PostalCode': 0,\n",
       " 'Price': 0,\n",
       " 'Province': 4,\n",
       " 'ShowerCount': 32311,\n",
       " 'StateOfBuilding': 0,\n",
       " 'SurfaceOfPlot': 0,\n",
       " 'SwimmingPool': 0,\n",
       " 'Terrace': 0,\n",
       " 'ToiletCount': 8791,\n",
       " 'TypeOfProperty': 0,\n",
       " 'TypeOfSale': 0}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna({\"Garden\" : 0}, inplace=True)\n",
    "df.fillna({\"SwimmingPool\" : 0}, inplace=True)\n",
    "df.fillna({\"Terrace\" : 0}, inplace=True)\n",
    "df.loc[(df[\"TypeOfProperty\"] == 1) & (df[\"SurfaceOfPlot\"].isna()), \"SurfaceOfPlot\"] = 0\n",
    "df.loc[(df[\"Garden\"] == 0) & (df[\"GardenArea\"].isna()), \"GardenArea\"] = 0\n",
    "\n",
    "df.isna().sum().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    StateOfBuilding  FloodingZone  Kitchen  PEB  SurfaceOfPlot  \\\n",
      "2               3.0           0.0      0.0  0.0            0.0   \n",
      "6               3.0           0.0      0.0  6.0          130.0   \n",
      "8               3.0           0.0      1.0  4.0            0.0   \n",
      "11              1.0           0.0      0.0  4.0            0.0   \n",
      "14              1.0           0.0      1.0  7.0            0.0   \n",
      "\n",
      "    ConstructionYear  NumberOfFacades  \n",
      "2             1969.0              2.0  \n",
      "6             1920.0              3.0  \n",
      "8             2008.0              2.0  \n",
      "11            1972.0              2.0  \n",
      "14            1994.0              2.0  \n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "# List of columns to be imputed\n",
    "columns_to_impute = [\"StateOfBuilding\", \"FloodingZone\", \"Kitchen\", \"PEB\", \"SurfaceOfPlot\", \"ConstructionYear\", \"NumberOfFacades\" ]\n",
    "\n",
    "# Fit and transform the data\n",
    "df[columns_to_impute] = imputer.fit_transform(df[columns_to_impute])\n",
    "for col in columns_to_impute : \n",
    "    df[col] = round(df[col])\n",
    "# Display the transformed columns\n",
    "print(df[columns_to_impute].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_attributes = list(df.select_dtypes(include=['object']).columns)\n",
    "numerical_attributes = list(df.select_dtypes(include=['float64', 'int64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BathroomCount', 'BedroomCount', 'ConstructionYear', 'FloodingZone',\n",
       "       'Garden', 'GardenArea', 'Kitchen', 'LivingArea', 'NumberOfFacades',\n",
       "       'PEB', 'PostalCode', 'Price', 'ShowerCount', 'StateOfBuilding',\n",
       "       'SurfaceOfPlot', 'SwimmingPool', 'Terrace', 'ToiletCount',\n",
       "       'TypeOfProperty', 'TypeOfSale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"Locality\", \"District\", \"Province\"], axis = 1, inplace= True)\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BathroomCount        4335\n",
       "BedroomCount            0\n",
       "ConstructionYear        0\n",
       "FloodingZone            0\n",
       "Garden                  0\n",
       "GardenArea              0\n",
       "Kitchen                 0\n",
       "LivingArea           7879\n",
       "NumberOfFacades         0\n",
       "PEB                     0\n",
       "PostalCode              0\n",
       "Price                   0\n",
       "ShowerCount         32311\n",
       "StateOfBuilding         0\n",
       "SurfaceOfPlot           0\n",
       "SwimmingPool            0\n",
       "Terrace                 0\n",
       "ToiletCount          8791\n",
       "TypeOfProperty          0\n",
       "TypeOfSale              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Price\"], axis = 1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 87336.00844715665\n",
      "R-squared: 0.7795768976211548\n",
      "Score train: 0.9187541007995605\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "score_train = regressor.score(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Score train: {score_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:206998.95377\n",
      "Mean Absolute Error: 79244.44968690092\n",
      "R-squared: 0.7867562770843506\n",
      "Score train: 0.9907063245773315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X = df.drop(columns=[\"Price\"], axis = 1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size= 0.2)\n",
    "\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "regressor = xgb.XGBRFRegressor(max_depth=50)\n",
    "\n",
    "# cross_val_scores = cross_val_score(regressor, X, y, cv=10)\n",
    "# # Print the cross-validation scores for each fold\n",
    "# print(\"Cross-validation scores for each fold:\", cross_val_scores)\n",
    "# # Print the mean cross-validation score\n",
    "# print(\"Mean cross-validation score:\", cross_val_scores.mean())\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = True)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "score_train = regressor.score(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Score train: {score_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for each fold: [0.82119668 0.77941024 0.72666525 0.81205142 0.80155497 0.81135844\n",
      " 0.80256396 0.76320163 0.76527555 0.76567496]\n",
      "Mean cross-validation score: 0.7848953115931596\n",
      "Mean Absolute Error: 78474.25173506683\n",
      "R-squared: 0.8003844739504511\n",
      "Score train: 0.9700837460724501\n",
      "Score test: 0.8003844739504511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(columns=[\"Price\"], axis=1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "\n",
    "# Initialize the regressor\n",
    "regressor = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(regressor, X, y, cv=10)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"Cross-validation scores for each fold:\", cross_val_scores)\n",
    "\n",
    "# Print the mean cross-validation score\n",
    "print(\"Mean cross-validation score:\", cross_val_scores.mean())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "score_train = regressor.score(X_train, y_train)\n",
    "score_test = regressor.score(X_test, y_test)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Score train: {score_train}')\n",
    "print(f'Score test: {score_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83379"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
